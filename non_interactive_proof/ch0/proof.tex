%
We define the following solver circuit $\widetilde{C}$ for $P^{(g)}$:
\begin{codeblock}
  \textbf{Circuit $\widetilde{C}^{\Gamma_V^{(g)}, \Gamma_H^{(g)}, hash, C} (x^{(k)}, \rho)$}
  \medskip

  \hrule

  \medskip

  \textbf{Oracle:} $\Gamma_V^{(g)}, \Gamma_H^{(k)}, hash, C$ \\
  \textbf{Input:} puzzles $x^{(k)}$, bitstring $\rho$\\
  \textbf{Output:} A bit $b \in \{0,1\}$
  \medskip\hrule\medskip
  Run $C^{\Gamma_V,\Gamma_H}(x^{(k)}, \rho)$ \\
  \IndI \If $C$ asks a hint query on $q$ \then\\
  \IndII \If $q \in P_{hash}$ \then\\
  \IndIII \return $\bot$\\
  \IndII \textbf{else}\\
  \IndIII answer the query using $\Gamma_H^{(k)}(q)$\\
  \\
  \IndI \If $C$ asks a verification query $(q, y_1, \dots, y_k)$ \then \\
  \IndII \If $q \in P_{hash}$ \textbf{then} \\
  \IndIII \return $(q, y_1, \dots, y_k)$ \\
  \IndII \textbf{else} \\
  \IndIII answer the verification query with 0 \\
  \return $\bot$
\end{codeblock}
%
\begin{lemma}
  For fixed $P^{(1)}$ and $hash$ the following statement is true
  \begin{align*}
    \underset{\pi^{(k)}, \rho}{\Pr}[CanonicalSuccess^{P^{(g)}, C, hash}(\pi^{(k)}, \rho) = 1]
    \leq \underset{\substack{ \pi^{(k)}, \rho \\(x^{(k)}, \Gamma_V^{(g)}, \Gamma_H^{(k)}) := P^{(g)}(\pi^{(k)})}}{\Pr}[\Gamma_V^{(g)} (\widetilde{C}^{\Gamma_V^{(g)}, \Gamma_H^{(k)}, hash}(x^{(k)}, \rho)) = 1].
  \end{align*}
\end{lemma}
%
\begin{proof}
We observe that for fixed $\pi^{(k)}, \rho$ if $C$ succeeds canonically, then for $(x^{(k)}, \Gamma_V^{(g)}, \Gamma_H^{(g)} := P^{(g)}(\pi^{(k)}))$ we have
\begin{align*}
\Gamma_V^{(g)} (\widetilde{C}^{\Gamma_V^{(g)}, \Gamma_H^{(g)}, hash}(\pi_1, \dots, \pi_k)) = 1.
\end{align*}
Using this observation, we conclude that
\begin{align*}
  &\underset{\pi^{(k)}, \rho}{\Pr}\left[CanonicalSuccess^{P^{(g)}, C, hash}(\pi^{(k)}, \rho) = 1\right] \\
  &\IndII = \underset{\pi^{(k)}, \rho}{\mathbb{E}}\left[\underset{}{\Pr}\left[CanonicalSuccess^{P^{(g)}, C, hash}(\pi^{(k)}, \rho) = 1\right]\right] \\
  &\IndII \leq \underset{\pi^{(k)}, \rho}{\mathbb{E}}\left[\underset{}{\Pr}\left[CanonicalSuccess^{P^{(g)}, \widetilde{C}, hash}(\pi^{(k)}, \rho) = 1\right]\right] \\
  &\IndII = \underset{\substack{\pi^{(k)}, \rho \\ \left(x^{(k)}, \Gamma_V^{(g)}, \Gamma_H^{(k)}\right) := P^{(g)}(\pi^{(k)})}}{\Pr}[\Gamma_V^{(g)} (\widetilde{C}^{\Gamma_V^{(g)}, \Gamma_H^{(k)}, hash}(x^{(k)}, \rho)) = 1].
\end{align*}
% hack to have square at the end of the proof
\\\text{  }
\end{proof}
%
Therefore, from a circuit $C$ we can build a circuit $\widetilde{C}$ that outputs $\bot$ or $(q, y_1, \dots, y_k)$ such that $q \in P_{hash}$.
Furthermore, the circuit $\widetilde{C}$ asks no verification queries, and every hint query on $q$ is such that $q \notin P_{hash}$.
%
%
\begin{lemma}\textbf{(Security amplification of a dynamic weakly verifiable puzzle with respect to $P_{hash}$.)}
  \label{lemma:sec_amp_for_p_hash}
  For fixed $P^{(1)}$ there exists an algorithm $Gen(C, g, \varepsilon, \delta, n, v, h, hash)$,
  which takes as input a solver circuit $C$ for $P^{(g)}$, a monotone function $g:\{0,1\}^{(k)} \rightarrow \{0,1\}$,
  a function $hash : Q \rightarrow \{0, \dots, 2(h+v)-1\}$, parameters $\varepsilon, \delta, n$,
  number of verification queries $v$ and hint queries $h$ asked by $C$, and outputs a circuit $D$
  such that the following holds: \\
  If $C$ is such that \\
  \begin{align*}
    \underset{\pi^{(k)}, \rho}{\Pr}\left[CanonicalSuccess^{P^{(g)}, C, hash}(\pi^{(k)}, \rho)=1\right] \geq \underset{\mu \leftarrow \mu_\delta^k}{\Pr}[g(\mu) = 1] + \varepsilon,
  \end{align*}
  then $D$ satisfies almost surely
  \begin{align*}
    \underset{\substack{\pi, \sigma \\ (x,\Gamma_V,\Gamma_H) := P^{(1)}(\pi)}}{\Pr}\left[\Gamma_V(D^{P^{(1)},C,\Gamma_V, \Gamma_H, hash}(x, \sigma)) = 1\right] \geq (\delta + \frac{\varepsilon}{6k}).
  \end{align*}
  Additionally, $Gen$ requires only oracle access to $g$, $P^{(1)}$ and $C$.
  Furthermore, $Size(D) \leq Size(C)\frac{6k}{\varepsilon}$ and $Time(Gen) = poly(k, \frac{1}{\varepsilon}, n, v, h)$.
\end{lemma}
%
\begin{proof}
First we define helper procedures \textbf{EvalutePuzzles} and \textbf{EvaluateSurplus}.
%
\begin{codeblock}
  $\textbf{EvaluatePuzzles}^{P^{(1)}, C, hash}(\pi^{(k)}, k)$
  \medskip \hrule \medskip
  \textbf{Oracle:}  A circuit $C$, an algorithm $P^{(1)}$, a function $hash$.\\
  \textbf{Input:} Bitstrings $\pi^{(k)}$, $\rho$, an integer $k$.\\
  \textbf{Output}: A tuple $(c_1, \dots, c_k)$.
  %
  \medskip\hrule\medskip
  $(x^{(k)}, \Gamma_V^{(g)}, \Gamma_H^{(k)}) := P^{(g)}(\pi^{(k)})$ \\
  $(q,y^{(k)}) := \widetilde{C}^{\Gamma_V^{(g)}, \Gamma_H^{(k)}, hash, C}(x^{(k)}, \rho)$\\
  %
  \For $i:=1$ to $k$ \Do \\
  \IndI $(x_i, \Gamma_V^{i}, \Gamma_H^{i}) := P^{(1)}(\pi_i)$\\
  \For $i:=1$ to $k$ \Do \\
  \IndI $c_i := \Gamma_v^{i}(q, y_i)$\\
  \return $(c_1, \dots, c_k)$\\
\end{codeblock}
%
\begin{todo}
  \textbf{TODO:} Figure out $N_K$\\
  \textbf{TODO:} Get a sample for $\Pr[g(b,\dots,b) = 1]$
\end{todo}
%
\begin{codeblock}
  $\textbf{EvaluateSurplus}(\pi^*, b, k)$
  \medskip
  \hrule
  \medskip
  \textbf{Oracle:} A circuits $C$, an algorithm $P^{(1)}$, a function $hash$.\\
  \textbf{Input:} A bistring $\pi^*$, a bit $b$, an integer $k$.\\
  \textbf{Output:} A circuit $D$.
  \medskip\hrule\medskip
  \textbf{For} $i:=1$ to $N_k$ \\
  \IndI $(\pi_2, \dots, \pi_k) \xleftarrow{\$} \{0,1\}^{(k-1)l}$\\
  \IndI $\rho \xleftarrow{\$} \{0,1\}^{*}$\\
  \IndI $(c_1, \dots, c_k) := \textbf{EvalutePuzzles}^{P^{(1)}, C, hash}(\pi^*, \pi_2, \dots, \pi_k, k)$\\
  \IndI $\widetilde{S}_{\pi^*,b}^i := g(b, c_2, \dots, c_k) - \underset{(u_2, \dots, u_k)}{\Pr}[g(b, u_2, \dots, u_k) = 1] $\\
  \textbf{return} $\frac{1}{N_k} \sum_{i=1}^{N_k} \widetilde{S}_{\pi^*,b}^i$\\
\end{codeblock}
%
\begin{codeblock}
  \textbf{Circuit $D^{C, P^{(1)}}(x^*, \sigma)$}
  \medskip \hrule \medskip
  \textbf{Oracle:} A circuit $C$, a poser $P^{(1)}$, a function $hash$.\\
  \textbf{Input:} A puzzle $x^*$, a bitstring $\sigma \in \{0,1\}^{*}$.\\
  \textbf{Output}: A circuit $D$.
  \medskip\hrule\medskip
  Let $k$ be the number of puzzles takes as input by $C$.\\
  \For $i:=1$ to $\frac{6k}{\epsilon} \log(\frac{6k}{\epsilon})$ \Do \\
  \IndI $\pi^{(k)} \leftarrow$ read $k\cdot l$ bits from $\sigma$ \\
  \IndI $(c_1, \dots, c_{k}) := \textbf{EvaluatePuzzles}^{P^{(1)}, C, hash}(\pi^{(k)}, k)$\\
  \IndI \If $g(1,c_2, \dots, c_k) =1 \land g(0,c_2, \dots, c_k) = 0$ \then \\
  \IndII \For $i:=1$ to $k$ \Do \\
  \IndIII $(x_i, \Gamma_V^{i}, \Gamma_H^{i}) := P^{(1)}(\pi_i)$\\
  \IndII $(q, y_1, \dots, y_{k}) := \widetilde{C}(x^*, x_2, \dots, x_{k})$\\
  \IndII \return $(q, y_1)$\\
  \return $\bot$ \\

\end{codeblock}
%
%
\begin{codeblock}
  \textbf{Algorithm $Gen(C, g, \epsilon, \delta, n, v, h, hash)$}
  \medskip
  \hrule
  \medskip
  \textbf{Oracle:} $C, g, hash$ \\
  \textbf{Input:}  $\epsilon, \delta, n, v, h$\\
  \textbf{Output:} A circuit $D$
  \medskip\hrule\medskip
  Let $k$ be the number of puzzles takes as input by $C$.\\
  \If $k = 1$ \then \\
  \IndI \return $\widetilde{C}$ \\ \\
  \textbf{For} $i:=1$ to $\frac{6k}{\epsilon}\log(n)$ \\
  \IndI $\pi^* \leftarrow \{0,1\}^{l}$\\
  \IndI $\widetilde{S}_{\pi^*,0} := \textbf{EvaluateSurplus}^{P^{(1)}, C, hash}(\pi^*, 0, k)$\\
  \IndI $\widetilde{S}_{\pi^*,1} := \textbf{EvaluateSurplus}^{P^{(1)}, C, hash}(\pi^*, 1, k)$\\
  \IndI \textbf{If} $\widetilde{S}_{\pi^*,0} \geq (1 - \frac{3}{4k}) \epsilon$ or $\widetilde{S}_{\pi^*,1} \geq (1 - \frac{3}{4k}) \epsilon$ \\
  \IndII $C' := C$ with the first input fixed on $\x^*$\\
  \IndII $g'(b_2, \dots, b_k) := g(c_1, b_2, \dots, b_k)$\\
  \IndII\textbf{return} $Gen(\widetilde{C}', g', \epsilon, \delta, n, v, h, hash)$ \\
  // all estimates are lower than $(1-\frac{3}{4k})\varepsilon$\\
  \return $D^{\widetilde{C}}$
\end{codeblock}
%
% The algorithm $Gen$ recursively builds the circuit that have high success probability in solving a dynamic weakly verifiable puzzle.
% When algorithm recurses it fixes a puzzle on the first position on the input of circuit $\widetilde{C}$ which yields a new circuit $\widetilde{C}'$.
% It happens only in the situation when for some fixed $\pi^*$ circuit $\widetilde{C}$ performs good on the remaining $k-1$ puzzles.
%
For $k=1$ the function $g: \{0,1\} \rightarrow \{0,1\}$ is either an identity or a constant function.
If $g$ is identity then the success probability of $\widetilde{C}$ is as least $\delta + \epsilon$
and $\widetilde{C}$ can be directly used to solve a puzzle. In case when $g$ is a constant function the statement is vacuously true.

Let $(q, y_1, \dots, y_k)$ denote the output of $\widetilde{C}$ and $c_i := \Gamma_V(q, y_i)$.
We define a surplus:
\begin{align}
  \label{eq:s_pi_b}
S_{\pi^*, b} = \underset{\pi^{(k)}}{\Pr}[g(b, c_2, \dots, c_k) = 1] - \underset{\mu^{(k)}}{\Pr}[g(b, u_2, \dots, u_k) = 1]
\end{align}
The surplus $S_{\pi^*, b}$ tells us how good $\widetilde{C}$ performs when the first puzzle is fixed, and instead $c_1$ the value $b$ is used.
The procedure \textbf{EvaluateSurplus} returns the estimate for $\widetilde{S}_{\pi^*, b}$.
All puzzles used during obtaining the estimate are generated internally.
Therefore, it is possible to provide answers for all hint and verification queries.
The returned estimate $\widetilde{S}_{\pi^*,b}$ differs from $S_{\pi^*, b}$ by at most $\frac{\epsilon}{4k}$ almost surely.
Therefore, if $\widetilde{S}_{\pi^*,b} \geq (1-\frac{3}{4k})\epsilon$ then $S_{\pi^*,b} \geq (1-\frac{1}{k})\epsilon$ almost surely, and
we fix the first bit of $g'(b_2, \dots, b_k) := g(b, b_2, \dots, b_k)$, and the first puzzle of $\widetilde{C}$ for the one generated from $\pi^*$ which yields a new circuit $\widetilde{C}'$.
The circuit $\widetilde{C}'$ satisfies the conditions of Lemma \ref{lemma:sec_amp_for_p_hash}
and we recurse using $\widetilde{C}'$ and the monotone function $g'$.

If all estimates are less than $(1-\frac{3}{4k})\epsilon$, then intuitively $\widetilde{C}$
does not perform much better on the remaining $k-1$ puzzles than an algorithm that solves each puzzle independent with probability $\delta$.
However, from the assumption we know that on all $k$ puzzles $\widetilde{C}$ has higher success probability.
Therefore, it is likely that the first puzzle is correctly solved with probability higher than $\delta$.
%
% \begin{todo}
%   \textbf{TODO:} Explain the intuition why it may happen that we still can fail in the case of circuit $\widetilde{D}$.
% \end{todo}
%
We now show that this intuition is indeed correct. For a fixed puzzle $x^*$ using (\ref{eq:s_pi_b}), we get
\begin{align}
\label{eq:diff_s01}
  &\underset{u \leftarrow \mu_{\delta}^k}{\Pr}[g(1, u_2, \dots, u_k)=1] - \underset{u \leftarrow \mu_{\delta}^k}{\Pr}[g(0, u_2, \dots, u_k)=1] = \notag\\
&\IndI  \underset{\pi^{(k)}}{\Pr}[g(1, c_2, \dots, c_k) =1 \mid \pi_1 = \pi^*] - \underset{\pi^k}{\Pr}[g(0, c_2, \dots, c_k) = 1 \mid \pi_1 = \pi^*] - (S_{\pi^*,1} - S_{\pi^*,0}).
\end{align}
% \begin{todo}
%   \textbf{TODO:} Better explain why we can write $\Pr(g() = 1 \land g() = 0)$ as the equivalence for the difference.
% \end{todo}
From the monotonicity of $g$ we know that for any set of tuples $(b_1, \dots, b_k)$
and sets $G_0 = \{ (b_1, b_2, \dots, b_k): g(0, b_2, \dots, b_k) = 1\}$, $ G_1 = \{(b_1, b_2, \dots, b_k) : g(1, b_2, \dots, b_k) = 1 \}$
we have $G_0 \subseteq G_1$. Hence, we can write (\ref{eq:diff_s01}):
\begin{align}
  \label{eq:diff_s01_next}
  &\underset{\mu_{\delta}^k}{\Pr}[g(1, \mu_2, \dots, \mu_k) = 1 \land g(0, \mu_2, \dots, \mu_k) = 0] = \notag\\
&\IndI  \underset{\pi^{(k)}}{\Pr}[g(1, c_2, \dots, c_k) = 1 \land g(0, c_2, \dots, c_k) = 0 \mid \pi_1 = \pi^*] - (S_{\pi^*,1} - S_{\pi^*,0}).
\end{align}
Let $G_{\mu^{(k)}}$ denote the event $g(1, u_2, \dots, u_k) = 1 \land g(0, u_2, \dots, u_k) = 0$, and correspondingly
$G_{\pi^{(k)}} := g(1, c_2, \dots, c_k) = 1 \land g(0, c_2, \dots, c_k) = 0$.
Then multiplying and dividing $\underset{}{\Pr}[\Gamma_V^{(g)}(D(x^*, \pi^{(k)})) = 1 \mid \pi_1 = \pi^*]$ by (\ref{eq:diff_s01_next}) we get
\begin{align}
\label{eq:pr_d_succ_0}
  \underset{r}{\Pr}[\Gamma_V^{(g)}(D(x^*, r)) = 1 \mid \pi_1 = \pi^*] &=
  \frac{\underset{r}{\Pr}[\Gamma_V^{(g)}(D(x^*, r)) = 1 \mid \pi_1 = \pi^*] \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*]} {\underset{u \leftarrow \mu_{\delta}^{k}}{\Pr}[G_{\mu}]} \notag\\
  & \IndI - \frac{\underset{r}{\Pr}[\Gamma_V^{(g)}(D(x^*, r)) = 1 \mid \pi_1 = \pi^*](S_{\pi^*,1} - S_{\pi^*,0})}{\underset{u \leftarrow \mu_{\delta}^{k}}{\Pr}[G_{\mu}]}
\end{align}
%
% \begin{todo}
%   \textbf{TODO:} Define $c_1, \dots, c_k$ correctly from the paper it is not known whether it is in the iteration or the final one
% \end{todo}
If output of $D(x^*,r) \neq \bot$ then we denote $c_i := \Gamma_V^{i}(q, y_i)$.
We can write the first summand of (\ref{eq:pr_d_succ_0}) as
\begin{align}
  &\underset{r}{\Pr}[\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi_1 = \pi^*] \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] = \notag\\
  &\IndI \underset{r}{\Pr}[D(x^*,r) \neq \bot \mid \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*]
\end{align}
where we make use of the fact that the event $G_{\pi}$ implies $D(x^*, r) \neq \bot$.
We consider two cases.
For $\underset{\pi^{k}}{\Pr}[g(1, c_2, \dots, c_k) = 1 \land g(0, c_2, \dots,c_k ) = 0 \mid \pi_1 = \pi^*] \leq \frac{\epsilon}{6k}$ then
\begin{align}
  \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*] \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] \leq \frac{\epsilon}{6k},
\end{align}
and when $\underset{\pi^{k}}{\Pr}[g(1, c_2, \dots, c_k) = 1 \land g(0, c_2, \dots,c_k ) = 0] > \frac{\epsilon}{6k}$ then circuit $D$ outputs $\bot$
only if it fails in all $\frac{6k}{\epsilon} \log(\frac{6k}{\epsilon})$ iterations to find $\pi^{(k)}$ such that $g(1, c_2, \dots, c_k) = 1 \land g(0, c_2, \dots, c_k) = 0$
which happens with probability
\begin{align}
\underset{r}{\Pr}[D(x^*,r) = \bot \mid \pi_1 = \pi^*] \leq (1 - \frac{\epsilon}{6k})^{\frac{6k}{\epsilon}\log(\frac{\epsilon}{6k})} \leq \frac{\epsilon}{6k}.
\end{align}
We conclude that in both cases:
\begin{align}
  &\underset{r}{\Pr}[D(x^*,r) \neq \bot \mid \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] \notag\\
  &\IndII \geq \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*]\underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] - \frac{\epsilon}{6k}.
\end{align}
Therefore, we have
\begin{align*}
  &\underset{r}{\Pr}[D(x^*,r) \neq \bot \mid \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] \notag\\
  &\IndII = \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \land g(1, c_2,\dots, c_k) = 1 \land g(0, c_2, \dots, c_k) = 0 \mid \pi_1 = \pi^*] - \frac{\epsilon}{6k} \\
  &\IndII = \underset{\pi^{(k)}}{\Pr}[g(c_1, c_2,\dots, c_k) = 1 \land g(0, c_2, \dots, c_k) = 0 \mid \pi_1 = \pi^*] - \frac{\epsilon}{6k} \\
  &\IndII = \underset{\pi^{(k)}}{\Pr}[g(c_1, c_2,\dots, c_k) = 1 \mid \pi_1 = \pi^*] -  \underset{\pi^{(k)}}{\Pr}[g(0, c_2, \dots, c_k) = 0 \mid \pi_1 = \pi^*] - \frac{\epsilon}{6k},
\end{align*}
and finally by (\ref{eq:s_pi_b})
\begin{align}
  &\underset{r}{\Pr}[D(x^*,r) \neq \bot \mid \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[c_1 = 1 \mid G_{\pi}, \pi_1 = \pi^*]
  \underset{\pi^{(k)}}{\Pr}[G_{\pi} \mid \pi_1 = \pi^*] \notag\\
  &\IndII = \underset{\pi^{(k)}}{\Pr}[g(c_1, c_2,\dots, c_k) = 1 \mid \pi_1 = \pi^*] -  \underset{\mu_{\delta}^{(k)}}{\Pr}[g(0, \mu_2, \dots, \mu_k) = 0 \mid \pi_1 = \pi^*]  - S_{\pi^*,0} - \frac{\epsilon}{6k}.
\end{align}
Inserting this result into the equation (\ref{eq:pr_d_succ_0}) yields
\begin{align}
\label{eq:pr_d_succ_1}
  &\underset{r,\pi}{\Pr}[D(x,r) = 1] = \mathbb{E_{\pi}}\left[\underset{r}{\Pr}[D(x,r) = 1 \mid \pi_1 = \pi^*]\right] \notag\\
&\IndI = \mathbb{E}_{\pi}\left[\frac{{\Pr}_{\pi^{(k)}}[g(c) = 1 \mid \pi_1 = \pi^*] -
{\Pr}_{\mu_{\delta}^{(k)}}[g(0, \mu_2, \dots, \mu_k) = 0 \mid \pi_1 = \pi^*] - \frac{\epsilon}{6k}} {{\Pr}_{\mu_{\delta}^{k}}[G_{\mu}]}\right] \notag\\
&\IndII - \mathbb{E}_{\pi}\left[\frac{
  S_{\pi^*,0} + \Pr_r [\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi_1 = \pi^*](S_{\pi^*,1} - S_{\pi^*,0})}
{{\Pr}_{\mu_{\delta}^{k}}[G_{\mu}]}\right]
\end{align}
For the second summand we show that if we do not recurse, then almost surely majority of estimates is low.
Let assume
\begin{align}
\underset{\pi}{\Pr}\left[\left(S_{\pi,0} \leq (1 - \frac{1}{2k})\epsilon\right) \land \left( S_{\pi,1} \leq (1-\frac{1}{2k})\epsilon\right)\right] < 1 - \frac{\epsilon}{6k},
\end{align}
then the algorithm recurses almost surely.
Therefore, under the assumption that $Gen$ does not recurse, we have almost surely
\begin{align}
\underset{\pi}{\Pr}\left[\left(S_{\pi,0} \leq (1 - \frac{1}{2k})\epsilon\right) \land \left( S_{\pi,1} \leq (1-\frac{1}{2k})\epsilon\right)\right] \geq 1 - \frac{\epsilon}{6k}.
\end{align}
Let us define a set
\begin{align}
  \cW = \left\{ \pi :  \left(S_{\pi,0} \leq (1 - \frac{1}{2k})\epsilon\right) \land \left( S_{\pi,1} \leq (1-\frac{1}{2k})\epsilon \right) \right\}
\end{align}
and use $\cW^c$ to denote the complement of $\cW$.
We bound the second summand in (\ref{eq:pr_d_succ_1})
\begin{align}
&\mathbb{E}_{\pi}\left[ S_{\pi^*,0} + \Pr_r [\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi_1 = \pi^*](S_{\pi^*,1} - S_{\pi^*,0}) \right] \notag\\
&\IndII = \mathbb{E}_{\pi \in \cW^c}\left[ S_{\pi^*,0} + \Pr_r [\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi = \pi^*](S_{\pi^*,1} - S_{\pi^*,0}) \right] \notag\\
&\IndIII +  \mathbb{E}_{\pi \in \cW}\left[ S_{\pi^*,0} + \Pr_r [\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi = \pi^*](S_{\pi^*,1} - S_{\pi^*,0}) \right] \\
&\IndII \leq \frac{\epsilon}{6k} + \mathbb{E}_{\pi \in \cW^c}\left[ S_{\pi^*,0} + \Pr_r [\Gamma_V^{(g)}(D(x^*,r)) = 1 \mid \pi = \pi^*]((1 - \frac{1}{2k})\epsilon - S_{\pi^*,0}) \right] \\
&\IndII \leq \frac{\epsilon}{6k} + 1 - \frac{\epsilon}{2k} = 1 - \frac{\epsilon}{3k}
\end{align}
Finally, we insert this result into equation (\ref{eq:pr_d_succ_1}) and make use of the fact
\begin{align*}
\underset{}{\Pr}[g(u) = 1] &= \underset{}{\Pr}[(g(0, \mu_2, \dots, \mu_k) = 1) \lor ( g(1,\mu_2, \dots, \mu_k) = 1 \land g(0, \mu_2, \dots, \mu_k) = 0 \land \mu_1 = 1)] \notag\\
&= \Pr[g(0,\mu_2, \dots,\mu_k) = 1] + \Pr[g(1,\mu_2,\dots,\mu_k) = 1 \land g(0, \mu_2, \dots, \mu_k) = 0] \Pr[\mu_1 = 1]
\end{align*}
which yields
\begin{align*}
  \underset{r,\pi}{\Pr}[D(x,r) = 1]
&\geq \mathbb{E}_{\pi}\left[\frac{{\Pr}_{\pi^{(k)}}[g(c) = 1 \mid \pi_1 = \pi^*] -
{\Pr}_{\mu_{\delta}^{(k)}}[g(0, \mu_2, \dots, \mu_k) = 0] - (1 - \frac{1}{6k})\epsilon} {{\Pr}_{\mu_{\delta}^{k}}[G_{\mu}]}\right] \notag
 \end{align*}
 Using the assumptions of Lemma \ref{lemma:sec_amp_for_p_hash}, we get
 \begin{align*}
   \underset{r,\pi}{\Pr}[D(x,r) = 1]
 &\geq \frac{ {\Pr}_{\mu_{\delta}^{(k)}}[g(\mu) = 1] + \epsilon +
 \Pr_{\mu_{\delta}^{(k)}}[g(0, \mu_2, \dots, \mu_k) = 0] - (1 - \frac{1}{6k})\epsilon}
 {\Pr_{\mu_{\delta}^{k}}[G_{\mu}]} \notag\\
 &\geq \frac{\epsilon +
\delta\Pr_{\mu_{\delta}^{(k)}}[G_{\mu}] - (1 - \frac{1}{6k})\epsilon}
{\Pr_{\mu_{\delta}^{k}}[G_{\mu}]} \geq \delta + \frac{\epsilon}{6k}
\end{align*}

\end{proof}
%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../master"
%%% End:
