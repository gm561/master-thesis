%
\subsection{The intuition behind the proof}
\label{section:intuition}
In this section we give the intuition behind the proof of Theorem \ref{th:sec_amp_for_dwvp}.
We refer to a puzzle solved by $\widetilde{D}$ as an \textit{input puzzle} and fix the notation as in Theorem~\ref{th:sec_amp_for_dwvp}.
First, we give the intuition behind the part of the proof that bases on \cite{canetti2005hardness, holenstein2011general}.
\paragraph{Technique of \cite{canetti2005hardness, holenstein2011general}}
The idea is to use the circuit $C$ to solve $k$ puzzles among which is the input puzzle, and
the remaining $k\!-\!1$ puzzles are generated.
If a position for the input puzzle is carefully chosen as well as the randomness used to generate the remaining puzzles,
then the input puzzle can be solved with the substantial probability almost surely.

More precisely, we try to fix the randomness used to generate a puzzle on the first position such that
the circuit $C$ satisfies the assumptions of Theorem \ref{th:sec_amp_for_dwvp}
for the $(k\!-\!1)$-wise direct product of puzzles (where the fact whether the puzzle on the first position is correctly solved is neglected).
The success probability on the remaining puzzles can be estimated using a natural sampling technique.

When it is possible to find this randomness, then we recursively solve the sub-problem for the $(k\!-\!1)$-wise direct product of puzzles.
If the recursion reaches $k=1$, then we can use $C$ directly to solve the input puzzle.

We cannot exclude the situation where in one of the recursive calls we cannot
find the randomness for the first position such that the success probability of $C$ for the $(k\!-\!1)$-wise direct product of puzzles is substantial.
Nevertheless, we know that $C$ has the substantial success probability when all positions are considered.
Hence, we conclude that the first coordinate is somehow important in the sense that $C$ solves a puzzle on this coordinate unusually often.
Therefore, it makes sense to place the input puzzle on this position.
All that is left is to find the randomness used to generate puzzles on the remaining positions
such that when the input puzzle is placed on the first position, then it is solved correctly often.

In Section \ref{subsec:chs} we describe the same approach for the special case where
non-interactive puzzles are considered and the function $g$ is such that all puzzles have to be correctly solved.
In that section we use Observation~\ref{obs:wvp_matrix} to conclude that the remaining puzzles should be chosen such that they
are all correctly solved by~ $C$.

Here we generalize this approach. Namely, we search for the randomness used to generate the remaining $k\!-\!1$ puzzles
such that when a puzzle on the first position was solved successfully, then the $k$-wise direct product of puzzles would be solved successfully,
and if a puzzle on the first position was unsuccessfully solved, then the $k$-wise direct product of puzzles would be also solved unsuccessfully.
This is the only case where solving a puzzle on the first position makes the difference.
For a function $g$ which requires all puzzles to be solved correctly,
this approach corresponds exactly to the one presented in~Section~\ref{subsec:chs} for weakly verifiable puzzles.

All puzzles except for the input puzzle are generated by $\widetilde{\Gen}$ or $\widetilde{D}$.
Therefore, it is possible to answer all hint and verification queries concerning these puzzles.
For the input puzzle to answer hint and verification queries we have to use the hint and verification oracles, respectively.

The above described approach cannot be directly used in the context of dynamic puzzles.
After choosing the position for the input puzzle we have to find the randomness from which the remaining puzzles are generated.
This requires running $C$ several times. In one of this runs $C$ can ask a hint query which prevents a later verification query from succeeding.
Therefore, it may happen that the success probability of $C$ in the consecutive runs decreases.

\paragraph{Technique of \cite{dodis2009security}}
We would like to ensure that no hint query is ever asked that could prevent a verification query from being successful.
To satisfy this requirement we used technique described in \cite{dodis2009security}.
The set $Q$ is partitioned into two sets. The set of advice queries contains these $q \in \cQ$ on which
$C$ is allowed to ask hint queries. The set of attacking queries is the set on which $C$ asks successful verification queries.
It turns out that it is possible to use a natural sampling technique to find a function that partitions $Q$ such that
the success probability of $C$ is still substantial.

\paragraph{Putting it together}
\begin{todo}
  \textbf{TODO:} describe our contribution
\end{todo}