\section{Previous results}
\label{st:previous_results}
Different types of weakly verifiable cryptographic primitives have been studied in a series of works
\cite{canetti2004hardness, Dodis:2009:SAI:1530441.1530450, DBLP:journals/corr/abs-1002-3534}.
This section is intended not only to give a short overview of techniques used in these works,
but aims also to provide some intuition and insight into the problem of hardness amplification
of dynamic interactive weakly verifiable puzzles.
\subsection{Result of R.Canetti, S.Halevi, and M.Steiner}
\label{subsec:chs}
The notion of the \textit{weakly verifiable puzzle} has been coined by R.Canetti, S.Halevi, and M.Steiner in the paper
\textit{Hardness amplification of weakly verifiable puzzles} \cite{canetti2004hardness}.
In comparison to Definition \ref{def:dwvp} the puzzles considered in \cite{canetti2004hardness} are neither dynamic nor interactive.
Moreover, the number of verification queries is limited to one.
This constitutes a simplified case to the one considered in this Thesis.
In this section we provide the definition of weakly verifiable puzzles (WVP) that closely follows the one contained in \cite{canetti2004hardness},
and state the theorem of hardness amplification of weakly verifiable puzzles stated in \cite{canetti2004hardness}.
Finally, we give an intuition behind the proof of this theorem.
It is noteworthy that the main proof of this Thesis, contained in Chapter \ref{ch:main_result},
uses many ideas from the paper of R.Canetti, S.Halevi, and M.Steiner \cite{canetti2004hardness}.
%
\begin{definition}[Weakly Verifiable Puzzles]
  \label{def:wvp}
A \textnormal{weakly verifiable puzzle} is defined by a pair of polynomial time algorithms:
a probabilistic puzzle--generation algorithm $G$ and a deterministic verification algorithm $V$.
We write $G(1^k, \rho)$ to denote that $G$ takes as input a bitstring $1^k$, where $k$ is a security parameter,
and as auxiliary input a bitstring $\rho \in \{0,1\}^{*}$ which is the randomness used by~$G$.
The algorithm $G$ outputs $p \in \{0,1\}^{*}$ and a check information $c \in \{0,1\}^{*}$.
The \textnormal{verifier} $V$ is a deterministic algorithm that takes as input $p$, $c$, an answer $a \in \{0,1\}^{*}$
and outputs $b \in \{0,1\}$.

A \textnormal{solver} $S$ for $G$ is a polynomial time probabilistic algorithm that
takes as input $p$ and outputs $a$. We denote the randomness used by $S$ as $\pi \in \{0,1\}^{*}$,
and define the \textnormal{success probability} of $S$ in solving a puzzle defined by $P$ as
\begin{align*}
  \underset{\substack{\rho \in \{0,1\}^{*}, \pi \in \{0,1\}^{*} \\ (p,c):=G(1^k, \rho) \\ a := S(p, \pi)}}{\Pr}\Big[ V(p,c,a) = 1\Big].
\end{align*}
We write $P := (G,V)$ to denote a weakly verifiable puzzle $P$ defined by algorithms $G$ and $V$.
\end{definition}
We compare the above definition with Definition \ref{def:dwvp}. First, we note that probabilistic polynomial time algorithms can be converted
into families of polynomial size circuits. Next, we see that in Definition \ref{def:wvp} the algorithm $G$ is parameterized by
a bitstring $1^k$ meaning that the length of a random bitstring taken by $G$ is bounded by $poly(k)$.
For a fixed $k$, without loss of generality, we can model the algorithm $G(1^k, \rho)$ as a polynomial size circuit
that does not take as input the bistring $1^k$, but just a bitstring $\rho$ of length $\mathit{poly}(k)$.
The security parameters from Definition \ref{def:wvp} and Definition \ref{def:dwvp} are not equivalent,
as in the later definition the security parameter limits the length of the random bistring.
Next, in Definition \ref{def:wvp} a verification algorithm takes as input $p$, $c$, $a$.
Again, without loss of generality, we can assume that bitstrings $p$ and $c$ are hard-coded
in the circuit $\Gamma_V$ from Definition \ref{def:dwvp}. Hence, the algorithm $V$ corresponds to $\Gamma_V$.
%
\begin{definition}[$n$-fold repetition of Weakly Verifiable Puzzles]
  \label{def:n-fold-rep}
  Let $n~\in~\N$, and a weakly verifiable puzzle $P = (G,V)$ be fixed.
  We define the $n$-fold repetition of $P$ as a weakly verifiable puzzle where the puzzle--generation algorithm
  $G^{(n)}$ takes as input $1^k$, $\rho \in \{0,1\}^{*}$ as an auxiliary input and outputs tuples $p^{(n)} := (p_1, \dotsc, p_n) \in \{0,1\}^{*}$ and $c^{(n)} := (c_1, \dotsc, c_k) \in \{0,1\}^{*}$,
  where for each $1 \leq i \leq n$ pair $(p_i, c_i)$ is an independent instance of weakly verifiable puzzles defined by $G$ with security parameter $k$ and $V$.
  Finally, the verification algorithm $V^{(n)}$ takes as input $p^{(n)}$, $c^{(n)}$, an answer $a^{(n)}$, and outputs $b \in \{0,1\}$
  such that $b = 1$ if and only if for all $1 \leq i \leq n$ we have $V(p_i, c_i, a_i) = 1$.
  We write $P^{(n)}$ to denote the $n$--fold repetition of $P$.
 \end{definition}
%
Moreover, the $n$-fold repetition of weakly verifiable puzzles is solved successfully if and only if all $n$ puzzles are solved successfully.
In this Thesis we are interested in a more general situation where a monotone function $g: \{0,1\}^{n} \rightarrow \{0,1\}$ is used to decide
which coordinates of the $n$-fold repetition of puzzles have to be solved correctly. A precise definition is given in Section \ref{st:main_theorem}.
Clearly, we can assume that $g$ is such that all coordinates have to be solved successfully which matches the case considered in Definition \ref{def:n-fold-rep}.

The main theorem proved in \cite{canetti2004hardness} states that it is possible to turn a good solver for
$P^{(n)}$ to a good solver for $P$.
%
\begin{theorem}[Hardness amplification of Weakly Verifiable Puzzles]
  \label{thm:wvp_chs}
Let $n:\N \rightarrow \N$ and $\delta: \N \rightarrow (0,1)$ be efficiently computable functions and $q \in \N$ a \textit{slackness parameter}.
Moreover, let $P = (G,V)$ be a weakly verifiable puzzle as in Definition \ref{def:wvp}. We denote the running time of the
puzzle--generation algorithm $G$ for $P$ by $T_G$, and of the verification algorithm $V$ for $P$ by $T_V$.
If $S^{(n)}$ is a solver for the $n$-fold repetition of $P$ that success probability is at least $\delta^{n}$
and running time is $T$, then there exists a solver $S$ for $G$ with success probability at least $\delta(1-\frac{1}{q})$ and with running time
$O\Big(\frac{nq^3}{\delta^{2n-1}}(T + nT_G + nT_V)\Big)$.
\end{theorem}
%
The following algorithm is used in R.Cannetti, S.Halevi, and M.Steiner to prove Theorem \ref{thm:wvp_chs}.
It uses a solver $S^{(n)}$ for the $n$-fold repetition of $P$ that succeeds with probability at least $\delta^{n}$
to solve a single puzzle with probability at least $\delta(1  - \frac{1}{q})$. Use a slackness parameter $q$ as it is not possible to achieve
the perfect hardness amplification. We note that in the analysis of running time of $\mathit{CHS\text{--}solver}$
we take into account time needed for oracle calls to $S^{(n)}, V, G$.
%
To make the notation shorter in the following code excerpts we do not write randomness used by the generator $G$ explicitly.
\begin{codeblock}
  \textbf{Algorithm:} $\mathit{CHS\text{--}solver}^{S^{(n)},V,G}(p, n, k, q, \delta)$
  \medskip\hrule
  \textbf{Oracle:} A solver $S^{(n)}$ for $P^{(n)}$, a verification algorithm $V$ for $P$, a puzzle--generation algorithm $G$ for $P$.\\
  \textbf{Input:}  A bistring $p \in \{0,1\}^{*}$, parameters $n, k, q, \delta$.
  \medskip\hrule
  $\mathit{prefix} := \emptyset$\\
  \For $i = 1$ \To $n-1$ \Do \\
  \IndI $p^* := \mathit{ExtendPrefix}^{S^{(n)}, V, G}(\mathit{prefix}, i, n, k, q, \delta)$\\
  \IndI \If $p^* = \bot$ \Then \Return $\mathit{OnlinePhase}^{S^{(n)}, V, G}(\mathit{prefix}, p, i, n, k, q, \delta)$ \\
  \IndI \Else $\mathit{prefix} := \mathit{prefix} \circ p^*$\\
  $ a^{(n)} := S^{(n)}(\mathit{prefix} \circ p)$ \\
  \Return $a_n$
\end{codeblock}
%
\begin{codeblock}
  \textbf{Algorithm:} $\mathit{OnlinePhase^{S^{(n)}, V, G}(\mathit{prefix}, p, v, n, k, q, \delta)}$
  \medskip \hrule
  \textbf{Oracle:} A solver algorithm $S^{(n)}$ for $P^{(n)}$, a puzzle--generation algorithm $G$ for $P$, a~verification algorithm $V$ for~$P$.\\
  \textbf{Input:} A $(v-1)$--tuple of bitstrings $\mathit{prefix}$, a bitstring $p \in \{0,1\}^{*}$, \\ parameters $v, n, k, q, \delta$.
  \medskip\hrule
  \Repeat $\Big\lceil\frac{6q \ln (6q)}{\delta^{n-v+1}}\Big\rceil$ times \\
  \IndI $((p_{v+1}, \dotsc, p_{n}),(c_{v+1}, \dots, c_n)) := G^{(n-v-1)}(1^k)$\\
  \IndI $a^{(n)} := S^{(n)}(\mathit{prefix}, p, p_{v+1}, \dotsc, p_n)$\\
  \IndI \If $\forall_{v+1 \leq i \leq n} V(p_i, c_i, a_i) = 1$ \Then \Return $a_v$\\
  \Return $\bot$
\end{codeblock}
%
\begin{codeblock}
  \textbf{Algorithm:} $\mathit{ExtendPrefix^{S^{(n)}, V, G}(prefix, i, n, k, q, \delta)}$
  \medskip \hrule
  \textbf{Oracle:} A solver algorithm $S^{(n)}$ for $P^{(n)}$, a puzzle--generation algorithm $G$ for $P$, a~verification algorithm $V$ for~$P$.\\
  \textbf{Input:} A $(i-1)$--tuple of puzzles $\mathit{prefix}$, parameters $i, n, k, q, \delta$.
  \medskip\hrule
  \Repeat $\Big\lceil \frac{6q}{\delta^{n-v+1}} \ln (\frac{18qn}{\delta}) \Big\rceil$ times \Do \\
  \IndI $(p^*, c^*) := G(1^k) $\\
  \IndI $\bar{\mu}_i := \mathit{EstimateResSuccProb}^{G,V}(\mathit{prefix} \circ p^*, i, n, k, q, \delta)$\\
  \IndI \If $\bar{\mu}_i \geq \delta^{n-i}$ \Then \Return $p^*$ \\
  \Return $\bot$
\end{codeblock}
%
\begin{codeblock}
  \textbf{Algorithm:} $\mathit{EstimateResSuccProb}^{S^{(n)},V, G}(\mathit{prefix}, i, n, k, q, \delta)$
  \medskip \hrule
  \textbf{Oracle:} A solver algorithm for $P^{(n)}$, a verification algorithm $V$ for $P$, a~generation algorithm $G$ for~$P$\\
  \textbf{Input:} A $(n-i)$--tuple of puzzles $\mathit{prefix}$, parameters $i, n, k, q, \delta$.
  \medskip\hrule
  $successes := 0$ \\
  \Repeat $M := \Big\lceil \frac{84q^2}{\delta^{n-i}} \ln \Big(\frac{18qn \cdot N_i}{\delta} \Big) \Big\rceil$ times \\
  \IndI $((p_{i+1}, \cdots, p_n), (c_{i+1}, \cdots, c_n)) := G^{(n-i)}(1^k)$\\
  \IndI $a^{(n)} := A(\mathit{prefix}, p_{i+1}, \cdots, p_{n})$\\
  \IndI \If $\forall_{1 \leq i \leq n} : V(p_i, c_i, a_i) = 1$ \Then $\mathit{successes := successes + 1}$ \\
  \Return $successes / M$
\end{codeblock}
%
%TODO: does this intuition works when $A$ is not deterministic i.e. cells then depends on the randomness of $A$.
A detail proof of Theorem \ref{thm:wvp_chs} is presented in \cite{canetti2004hardness}.
We limit ourselves to providing an intuition why the above algorithm to transfrom a good solver
for $n$--wise direct product of $P$ to a good solver for $P$.

Let us consider the $n$-fold repetition of $P$, and a deterministic solver $S^{(n)}$ for $P^{(n)}$.
Furthermore, we denote by write $p^{(n)}, c^{(n)}$ to denote the output of $G^{(n)}$.
We define a matrix $M$ as follows. The columns of $M$ are labeled with all possible bitstrings $p_1$
whereas the rows corresponds to all possible tuples $(p_2, \dotsc, p_n)$ where $G^{(n)}$ is executed with different randomness.
A cell of $M$ contains a binary $n$-tuple such that the $i$-th bit equals $1$ if and only if $V_i(p_i, c_i, a_i) = 1$, where
 $a^{(n)} := S^{(n)}(p^{(n)})$ and $p^{(n)}$ is a tuple of bitstring inferred by a column and row of the cell.
We make the following observation, with a simplifying assumption that the problem solver is deterministic.
\begin{observation}
\label{obs:wvp_matrix}
For a deterministic polynomial time algorithm $S^{(n)}$ that successfully solves the $n$-fold repetition of $P$ with probability at least $\delta^{n}$,
the matrix $M$ defined as above has either a column with $\delta^{(n-1)}$ fractions of cells that are all one vectors, or
a conditional probability that a cell is of the form $1^n$ given that the last $(n-1)$ bits of the cell are equal 1 is at least $\delta$.
\end{observation}
%
% /TODO put the proof in appendix? but the proof is trivial!
%
We show how the algorithm $\mathit{CHS\text{--}solver}$ uses Observation \ref{obs:wvp_matrix} to solve WVP with probability at least $\delta(1 - \frac{1}{q})$.
The algorithm starts with the first position and tries to fix a puzzle such that the success probability of $S^{(n)}$ on the remaining $(n-1)$
position is at least $\delta^{(n-1)}$. If it is possible to find $p^*$ such that this condition is satisfied, then we fix this $p^*$
on this position and repeat the whole procedure again in the consecutive iteration for the next position.
If $\mathit{CHS\text{--}solver}$ fails to find such a bitstring $p^*$, then we assume that there is no column of $M$ that contains $\delta^{(n-1)}$ fraction
of cells that are of the form $1^n$. We use Observation \ref{obs:wvp_matrix} and hope that the conditional probability of
solving the first puzzle given that all puzzles on the remaining position are solved successfully is at least $\delta$.
We place $p$ (which denotes the input puzzle) on this position and note that all remaining puzzles are generated by $\mathit{CHS\text{--}solver}$.
Thus, it is possible to efficiently verify whether these puzzles are successful solved by $S^{(n)}$.

Obviously, the algorithm $\mathit{CHS\text{--}solver}$ can still fail. First, it may happen that it does not find a column
with a high fraction of puzzles that are solved successfully, although such a column exists.
Secondly, we can not exclude a situation where no such column exists, but the algorithm fails to find a cell such that last $(n-1)$ bits are 1.
Finally, it is also possible that an estimate returned by $\mathit{EstimateResSuccProb}$ is incorrect.

It is possible to show that all these events happen with negligible probability.
Therefore, at least intuitively we see that the algorithm $\mathit{CHS\text{--}solver}$
solves a single WVP puzzle successfully with probability at least $\delta(1-\frac{1}{q})$ almost surely.

In Chapter \ref{ch:main_result} we study a more general class of puzzles that are not only weakly verifiable but also dynamic and interactive.
Furthermore, we allow a more general situation when a solver successfully solves the $n$-fold repetition of puzzles
\footnote{Actually, in Chapter \ref{ch:main_result} we define the $k$-wise repetition of puzzles
which in case of WVP is equivalent to the $n$-fold repetition of puzzles.}
although it solved successfully only on a subset $S \subset \{1,2,\dotsc, n\}$ of puzzles $P$.

It turns out that it is possible to use a similar technique of fixing puzzles on consecutive positions of the $n$-fold repetition of
puzzles to prove the hardness amplification in this more general case.
%
\subsection{Results of Y.Dodis, R.Impagliazzo, R.Jaiswal, V.Kabanets}
\label{subsec:dijk}
Some of the cryptographic constructions presented in Section~\ref{section:wvp_examples}
are not only weakly verifiable but also dynamic (MAC and SIG). This type of puzzles are defined and studied in \cite{Dodis:2009:SAI:1530441.1530450}.
We give a short overview of this work, state the definition of a \textit{dynamic weakly verifiable puzzle} that closely follows
the one included in \cite{Dodis:2009:SAI:1530441.1530450}. Finally, we provide intuition for the proof of the hardness amplification of DWVP
included in \cite{Dodis:2009:SAI:1530441.1530450}.

\begin{definition}[Dynamic Weakly Verifiable Puzzle.]
  \label{def:dwvp_dodis}
  A \textnormal{dynamic weakly verifiable puzzle} (DWVP) is defined by a distribution $\cD$ on pairs $(x, \alpha)$
  where $\alpha \in \{0,1\}^{*}$ is an advice used to generate and evaluate responses to $x \in \{0,1\}^{*}$.
  Furthermore, we consider a set $\cQ$ of indices and a probabilistic polynomial--time computable relation $R$ such that
  $R(\alpha, q, r) = 1$ if and only if $r$ is a correct answer to $q \in \cQ$ on the set of puzzle determined by $\alpha$.
  Finally, let $H(\alpha, q)$ be a probabilistic polynomial--time computable \textnormal{hint} relation.

  A solver $S$ takes as input $x$ and can ask hint queries on $q \in \cQ$ which are answered using $H(\alpha, q)$ and verification queries $(q,r)$
  that answers whether $R(\alpha,q,r)~=~1$. We say that $S$ succeeds if and only if it makes a verification query on $(q,r)$ such that it
  has not previously asked for a hint query on this $q$. We write $P := (\cD, R, H)$ to denote a DWVP with a distribution
  $\cD$ of pairs $(x, \alpha)$, and $R$, $H$ being a verification and hint relations respectively.
\end{definition}
%
The definition stated in Section \ref{def:dwvp} generalizes for dynamic weakly verifiable puzzles.
Instead of considering a distribution on pairs $(x,\alpha)$ we use a problem poser.
Furthermore, the problem poser may interact in the first phase with the problem solver.
Thus, in our case the distribution of puzzles is defined by both the problem poser and the problem solver.
The hint and verification relations corresponds to the hint and verification circuits generated by the problem poser.
%

We define the \textit{$n$-wise direct product of DWVPs}, which is conceptually similar to the $n$-fold repetition of WVPs.
%
\begin{definition}[$n$-wise direct product of DWVPs]
For a dynamic weakly verifiable puzzle $P~:=~(\cD, R, H)$ we define the $n$-wise direct product of $P$
as a DWVP with a distribution $\cD^n$ on tuples $(x_1, \alpha_1), \dotsc, (x_n, \alpha_n)$.
Furthermore, the hint relation is defined by $H^n(q, \alpha_1, \dotsc, \alpha_n) := (H(\alpha_1, q), \dotsc, H(\alpha_n, q))$ and
the verification relation $V^n(q, x_1, \dotsc, x_n)$ evaluates to $1$ if and only if
for $1 \leq i \leq n$ at least $n - (1 - \gamma)\delta n$ is such that $V(q, x_i,\alpha_i)~=~1$
where $0~\leq~\gamma,\delta~\leq~1$.
%
We write $P^{(n)} := (D^{(n)}, H^{(n)}, V^{(n)})$ to denote the $n$-wise direct product of $P := (D,H,V)$.
%
\end{definition}

In contrast to the $n$-fold repetition of puzzles defined in previous section, here we
require a solver to succeed only on the fraction of puzzles.

\begin{theorem}
Let $S^{(n)}$ be a probabilistic algorithm for the $P^{(n)}$ that succeeds with
probability at least $\epsilon$, where $\epsilon \geq (800/\gamma\delta) \cdot (h+v) \cdot e^{-\gamma^2\delta n/40}$, and $h$ and $v$
denote the number of hint and verification queries asked by $S^{(n)}$ respectively.
Then there exists a probabilistic algorithm $S$ that succeeds in solving $P$ with probability at least
$1-\delta$ making $O(h(h+v)/\epsilon) \cdot \log(1/\gamma\delta)$ hint queries and at most one verification query.
Furthermore, the running time $\mathit{poly}(h,v,\frac{1}{\epsilon}, t, \omega, \log(1/\gamma\delta))$ where
$\omega$ is time needed to ask a single hint query.
\end{theorem}

We define the \textit{success probability} of a solver $S$ for DWVP as
\begin{todo}
  \textbf{TODO:} Define success probability
\end{todo}

It worth seeing why the approach presented in the previous section can not be applied in the setting of dynamic weakly verifiable puzzles
(moving aside for a moment the issue of solving only a fraction of puzzle successfully).
For DWVP the algorithm $\mathit{CHS\text{--}solver}$ breaks in the $\mathit{OnlinePhase}$ where
the solver $S^{(n)}$ can be called multiple times.
It is possible that in one of these runs $S^{(n)}$ asks a hint query on $q$
for which in one of the later runs a verification query $(q,r)$ is asked
that would make $\mathit{CHS\text{--}solver}$ successfully solves the input puzzle.
Thus, we can not dismiss the situation where the success probability
of the solver $S^{(n)}$ decrease in after some iterations.

The solution proposed in \cite{Dodis:2009:SAI:1530441.1530450} is to partition the set $Q$ into a set of \textit{attacking queries} $Q_{\mathit{attack}}$
and a set of \textit{advice queries} $Q_{\mathit{adv}}$. The idea is to allow a solver for the $n$-wise direct product to ask a hint
queries only on $q \in Q_{\mathit{adv}}$, and to halt the execution whenever a hint query is asked on $q \in Q_{\mathit{attack}}$.

It is possible, for a solver $S$ that asks at most $h$ hint queries and $v$ verification queries,
to find a function $Q \rightarrow \{0,1,\dotsc 2(h+v)\}$ such that the success probability of $S$ with respect to
$Q_{\mathit{attack}}$ and $Q_{\mathit{adv}}$ is multiplied by $O(\frac{1}{h+v})$.
If $h$ and $v$ are not to big then the success probability of $S$ can still be substantial.

Additionally, we define a canonical success probability with respect to a $\hash$ function as
\begin{todo}
  \textbf{TODO:} Define success probability and canonical success probability
\end{todo}

More formally, in \cite{Dodis:2009:SAI:1530441.1530450} the following lemma is proved.
\begin{lemma}
Let $S$ be a solver for DWVP which success probability is at least $\epsilon$, the running time is at most $t$,
and the number of hint and verification queries is at most $h$ and $v$ respectively,
there exists a probabilistic algorithm that runs in time $poly(h,v,\frac{1}{\epsilon},t)$
that outputs a function $\hash : Q \rightarrow \{0,1, \dotsc, 2(h+v)\}$ such that the canonical
success probability of $S$ with respect to $\hash$ is at least $\frac{\epsilon}{8(h+v)}$.
\end{lemma}
A function $\hash$ can be found by using a natural sampling technique.
We follow the same approach of domain partitioning in Section \ref{st:domain_partition}.
%
Let $H_{\alpha}(q)$ denote a polynomial time probabilistic algorithm that takes as input $q$,
has hard-coded $\alpha$ and outputs $H(\alpha, q)$.
%
\begin{codeblock}
  \textbf{Algorithm:} $\mathit{DWVP\text{--}solver}^{S^{(n)}, \hash, H_{\alpha}^{(n)}, R_{\alpha}^{(n)}}(x)$
  \medskip
  \hrule
  \textbf{Oracle:}  A solver $S^{(n)}$ for $P^{(n)}$, a function $hash : Q \rightarrow \{0,1, \dotsc, 2(h+v)\}$.\\
  \textbf{Input:} A bistring $x \in \{0,1\}^{*}$.
  \medskip\hrule
  \Repeat at most $O(\frac{h+v}{\epsilon} \cdot \log(\frac{1}{\gamma\delta}))$ times \\
  \IndI Choose uniformly at random position $i \in \{1, \dotsc, n\}$ for $x$.\\
  \IndI Generate $(x_1, \alpha_1), \dotsc, (x_{i-1}, \alpha_{i-1}), (x_{i+1}, \alpha_{i+1}), \dotsc, (x_n, \alpha_n)$ \\
  \IndI using $(n-1)$ calls to $P$ each time with the fresh randomness.\\
%  \IndI $S_v$ //TODO what is this a Bug ??\\
  \IndI \Run $S^{(n)}(x_1, \dotsc, x_{i-1}, x, x_{i+1}, \dotsc, x_n)$\\
  \IndII \If $S^{(n)}$ asks a hint query on $q$ \Then \\
  \IndIII \If $hash(q) \neq 0$ \Then abort current run of $S^{(n)}$\\
  \IndIII Ask a verification query $r := H(q)$\\
  \IndIII Let $(r_1, \dotsc, r_{i-1}, r_{i+1}, \dotsc, r_{n})$ be hints for query $q$ for puzzle\\
  \IndIII sets $(x_1, \dotsc, x_{i-1}, x_{i+1}, x_n)$\\
  \IndIII Answer the hint query of $S^{(n)}$ using $(r_1, \dots, r_{i-1}, r, r_{i+1}, r_n)$\\
  \IndII \If $S^{(n)}$ asks a verification query $(q, r_1, \dots, r_n)$ \Then \\
  \IndIII \If $hash(q) = 0$ \Then answer the query with $0$\\
  \IndIII Let $m := |j: V(q,r_j) = 1, j \neq i|$\\
  \IndIII \If $m \geq n - n(1-\gamma)\delta$ \Then \\
  \IndIIII make a verification query $(q, r_i)$ and halt.\\
  \IndIII \Else with probability $\rho^{m - n(1-\gamma)\delta}$ ask a verification query \\
  \IndIIII $(q, r_i)$ and halt. \\
  \IndIII Halt the current run of $S^{(n)}$ and go to the next iteration.\\
  \Return $\bot$
\end{codeblock}

The above algorithm substantially differ from the one used in \cite{canetti2004hardness}.

In the above algorithm we execute multiple times a solver $S^{(n)}$ for the $k$-wise direct product of DWVPs.
In each iteration the position for $x \in \{0,1\}^{*}$ is chosen uniformly at random.
The remaining $(n-1)$ puzzles are generated by the algorithm, thus it is possible to answer
all hint and verification queries for these puzzles.
We use a function $\hash$ to partition the query domain.
We assume that $\hash$ is such that the success probability of $S^{(n)}$ with respect to $\hash$ is at least $\frac{\delta}{8(h+v)}$.
We check on which $q$ the solver $S^{(n)}$ asks hint and verification queries.
If a hint query is asked on $q$ such that $hash(q) = 0$ then the execution of $S^{(n)}$
is aborted and we goto to the next iteration. This way me make sure that the algorithm
never asks a hint query that could prevent a verification query to succeed.

%TODO unfold this a bit more
If a verification query is asked on $q$ such that $hash(q) \neq 0$ we answer such a verification
query with $0$.

Finally, in case when $S^{(n)}$ asks a verification query using index $q$ such that $hash(q) = 0$, then
we use a soft decision system to decide whether to ask a verification query.
The idea is that if there are many puzzles among the ones generated by the algorithm is solved correctly
then it is likely that also the input puzzle is solved correctly. We also have to discount
$\gamma\delta n$ to take into account that we require not all puzzles to be solved successfully.
The detail calculations provided in \cite{Dodis:2009:SAI:1530441.1530450} shows that this approach
yields a demanded result. More details can be found in \cite{Dodis:2009:SAI:1530441.1530450, impagliazzo2007chernoff}.

\begin{todo}
  \textbf{TODO:} Say why it makes sense to consider a threshold function\\
\end{todo}
In case of weakly verifiable primitives like CAPTCHAs we want to distinguish between humans and computers.
We assume that most people have slightly higher probability of solving these kind of puzzles than the best algorithms.
Still, it may happen that humans do not solve all puzzles. Therefore, we would like to introduce a threshold function
such that on average solutions of humans are treated as solved successfully but the ones of computer programs are classified
as not successful. This is a motivation to study the situations where only some fractions of puzzles is solved successfully.

In Chapter \ref{ch:main_result} we consider a weakly verifiable puzzles that are interactive and dynamic.
We use similar technique to partition domain $Q$ into advice and hint queries as presented in \cite{Dodis:2009:SAI:1530441.1530450}.
Instead of the requirement to succeed only on the fraction of puzzles we consider an arbitrary, monotone function $g : \{0,1\}^{n} \rightarrow \{0,1\}$
that determine on which coordinates the solver has to succeed in order to successfully solve the $n$-wise direct product of puzzles.

To show the hardness amplification for the $n$-wise direct product with the domain partitioned we use
the approach similar to the one presented in Section \ref{subsec:chs}. Namely, we try to find a good position for the input puzzle instead of
choosing this position on random as in \cite{Dodis:2009:SAI:1530441.1530450}.

\begin{todo}
  \textbf{TODO:} Give more intuition behind the proof i.e. why it works? why it is complicated.
\end{todo}

\subsection{Results of T.Holenstein and G.Scheonebeck}
The interactive weakly verifiable puzzles have been studied in \cite{DBLP:journals/corr/abs-1002-3534}.
An example of interactive weakly verifiable puzzles are bit commitments and CAPTCHAs.
Additionally, in \cite{DBLP:journals/corr/abs-1002-3534} a more general case is introduced when
which puzzles of the $n$-fold repetition should be solved is determined by a monotone function.

Interactive weakly verifiable puzzles has been defined in \cite{DBLP:journals/corr/abs-1002-3534} as follows:
\begin{definition}
An \textit{interactive weakly verifiable puzzle} is defined by a protocol given by two algorithms $P$ and $S$,
where $P$, called the problem poser, produces as output a verification circuit $\Gamma$. The algorithm $S$ called the problem solver
produces no output.
Furthermore, the \textnormal{success probability} of algorithm $S$ in solving a wealky verifiable puzzle is $(P,S)$ is:
\begin{align*}
  \Pr\Big[y := \langle P,S \rangle_{S}; \Gamma(y) = 1 \Big].
\end{align*}
\end{definition}
\begin{definition}[$k$-wise direct product of interactive weakly verifiable puzzles]
Let $g: \{0,1\}^{k} \rightarrow \{0,1\}$ be a monotone function, and $(P,S)$ be a fixed interactive weakly verifiable puzzle.
The $k$-wise direct product of $(P,S)$ is an interactive weakly verifiable puzzles in which the sender and the receiver
sequentially create $k$ instance of $(P,S)$, which yields circuits $\Gamma^{(1)}, \dotsc, \Gamma^{(k)}$ for $P$.
Finally, $P^{(g)}$ outputs the circuit $\Gamma^{(g)}(y_1, \dotsc, y_k) := g(\Gamma^{(1)}(y_1), \dotsc, \Gamma^{(k)}(y_k))$.
\end{definition}

In comparison to our definition the puzzles considered in \cite{DBLP:journals/corr/abs-1002-3534} are clearly not dynamic.
The circuit $\Gamma$ generated by $P$ corresponds to the verification circuit in Definition \ref{def:dwvp}.
Clearly, the hint circuit is not created.

Finally, T.Holenstein and G.Schonebeck proves the following hardness amplification therorem.
\begin{theorem}
There exists an algorithm $\mathit{Gen}(C,g,\epsilon, \delta, n)$ which takes as input a solver circuit $C$ for $k$-wise
direct product of $P$, a monotone function $g: \{0,1\}^{*} \rightarrow \{0,1\}$, and parameters $\epsilon,\delta,n$.
The algorithm $\mathit{Gen}$ outputs a solver circuit $D$ for $P$ such that the following holds.
If $C$ is such that
\begin{align*}
\Pr\Big[\Gamma^{(g)}(\Big\langle P^{(g)}, C \Big\rangle_C = 1) \Big] \geq \Pr_{u \leftarrow \mu_{\delta}^{(k)}} \Big[ g(u) = 1 \Big] + \epsilon,
\end{align*}
then, $D$ satisfies almost surely,
\begin{align*}
  \Pr\Big[ \Gamma^{(1)}(\rangle P^{(1)}, D\rangle_{D}) = 1\Big] \geq \delta + \frac{\epsilon}{6k}.
\end{align*}
Additionally, $\mathit{Gen}$ and $D$ only require oracle access to $g$ and $C$.
Furthermore, $\mathit{Size}(D) \leq \mathit{Size}(C) \cdot \frac{6k}{\epsilon} \log(\frac{6k}{\epsilon})$,
and $\Time (\mathit{Gen}) = \poly(k, \frac{1}{\epsilon}, n)$ with oracle calls to $C$.
\end{theorem}

First, we notice that the above intuition does not impose any restrictions on the time complexity of the poser and the solver.
In previous sections we considered solvers for the $n$-wise direct product that were compared with the algorithms that either
solves all puzzles (in \cite{canetti2004hardness}), or allowed a fraction of puzzles to be solved incorrectly (\cite{Dodis:2009:SAI:1530441.1530450}).
In the above definition a monotone function $g$ is considered which generalizes the previous approaches as in \cite{canetti2004hardness}
the function $g$ is a multiplication of all bits, and in \cite{Dodis:2009:SAI:1530441.1530450} $g$ is a threshold function that takes value
one if and only if a given fraction of puzzles is solved successfully.
Furthermore, we emphasize that a monotone restriction on $g$ is essential. Otherwise, for example in case of $g(b) := 1 - b$ an algorithm that
deliberately give incorrect solutions satisfies $g$ with probability one whereas an algorithm that solves a puzzle successfully with probability
$\gamma$ succeeds only with probability $1 - \gamma$.
A desirable property is that an algorithm that solves puzzles with the higher probability performance better than algorithm that success probability is lower.

The proof of T.Holenstein and G.Schoenebeck is similar to the one of R.Canettif and S.Halevi and M.Steiner presented in Section \ref{subsec:chs}.
Similarly, we use the technique to fix consecutive coordinates such that according invariant is maintained.
First in order to estimate how much better a solver circuit $C$ for $n$-wise direct product performs when
a puzzle on the first position is fixed a notion of a surplus $S_{\pi^*, b}$ is introduces:
\begin{align*}
S_{\pi^*, b} := \Pr_{\pi^{(k)}} [ c \in \cG_b | \pi_1 = \pi^* ] - \Pr_{u \leftarrow \mu_{\delta}^{k}} [u \in \cG_b],
\end{align*}
which intuitively tells us how much better a solver $C$ performs when a first puzzle is always solved correctly (case when $b = 1$)
or is always solved incorrectly (when $b = 0$).
Now we observe the following fact. If there exists a puzzle which is fixed on the first position for which the surplus is bigger than
$(1 - \frac{1}{k})\epsilon$ then we can fixed a this first puzzle and inductively solve the problem for the $(k-1)$-direct product of puzzles.
\begin{todo}
  \textbf{TODO:} what do it mean
\end{todo}
On the other hand, if we there is no such puzzle to fix on the first position it means that when we fix the first bit of $g$ then
the performance between the solver $C$ and an algorithm that solves puzzle on each position independently with probability $\delta$
is similar. However, we know that when the first bit of a function $g$ is not fixed then the solver $C$ is better.
Thus, we draw a conclusion that the puzzle on the first position has to be solved unusually often.

In a case it would be possible to fix all $(k-1)$ puzzles except the last one, the proof become trivial as we know that a function
$g$ with the first $k-1$ bits fixed is either the identity or a constant function.
%TODO write why it is true in this case

Thus, it is enough to show that if it is not possible to find an estimate that is low then
if we place an input puzzle on this position and we can find remaining $k-1$ puzzle such that
$c \in \cG_1 \setminus \cG_0$ then this puzzle is solved with substantial probability.
The whole proof is given in \cite{DBLP:journals/corr/abs-1002-3534}, and requires some probability manipulations.
Here, we give a present a simplified version where we assume that once we find a good position on which we can place the input puzzle then
we can always find remaining $k-1$ puzzles.
% \begin{align*}
%   \Pr_r\Big[ \Gamma^*(D(x^*,r)) = 1\Big] = \Pr_r\Big[\Gamma^*(D(x^*,r)) \neq \bot \Big]
% \end{align*}

Out proof of hardness amplification for dynamic interactive weakly verifiable puzzles closely follows the one given in \cite{DBLP:journals/corr/abs-1002-3534}.
\begin{todo}
  \textbf{TODO:} Why do we consider fixing 0/1 on the first position
  \textbf{TODO:} How the technique is generalized to approach of CHS \\
  \textbf{TODO:} Explain why we compare to such a probability i.e. why we consider with $\mu$ \\
  \textbf{TODO:} Why the requirement for $g$ being a monotone function is interesting \\
  \textbf{TODO:} Give the intuition behind the proof. \\
  \textbf{TODO:} Give a proof under the simplified assumptions? \\
  1) The algorithm always output an answer \\
  2) For every pi the surpluses $S_{\pi^*, 0}$ and $S_{\pi^*, 1}$ re less than $(1-\frac{1}{k})\epsilon$.\\
\end{todo}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
